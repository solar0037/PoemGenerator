{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"mount_file_id":"1ZTxt8M2g_lws2uf1yShhfujndYzqQl1g","authorship_tag":"ABX9TyOas/T1491pEPSmAo/gNmwH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qawaZUn_w7T5","colab_type":"text"},"source":["Colab Jupyter Notebook Version."]},{"cell_type":"code","metadata":{"id":"EAhVvrGlqU65","colab_type":"code","colab":{}},"source":["import re\n","import requests\n","from bs4 import BeautifulSoup\n","\n","\n","def get_poem():\n","    title, poem = [], []\n","    for i in range(1, 51):\n","        url = requests.get('https://yoondongju.yonsei.ac.kr/poet/poem.asp?ID=' + str(i))\n","\n","        bs_obj = BeautifulSoup(url.content.decode('euc-kr', 'ignore').encode('utf-8'), 'html.parser')\n","        data = bs_obj.find('div', {'id': 'con'})\n","\n","        data_title = data.find('p', {'id': 'title'})\n","        title_text = data_title.text\n","\n","        poem_text = re.sub('<br>', '\\n', re.sub(r'<br/>', '\\n', str(data)))\n","        poem_text = poem_text[poem_text.find('</p>') + 4:poem_text.find('<a') - 2]\n","\n","        title.append(title_text)\n","        poem.append(poem_text)\n","\n","        if i < 10:\n","            n = '0' + str(i)\n","        else:\n","            n = str(i)\n","\n","        with open('./drive/My Drive/Colab/PoemGenerator/poems/poem' + n + '.txt', 'w', encoding='utf-8') as f:\n","            f.write(poem_text)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oPpqqO9oqWzH","colab_type":"code","colab":{}},"source":["import numpy as np\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","\n","def build_model(vocab_size, max_len):\n","    model = Sequential()\n","    model.add(Embedding(vocab_size, 32, input_length=max_len - 1))\n","    model.add(LSTM(256, return_sequences=True, kernel_initializer='glorot_uniform'))\n","    model.add(LSTM(256, return_sequences=True, kernel_initializer='glorot_uniform'))\n","    model.add(LSTM(256, kernel_initializer='glorot_uniform'))\n","    model.add(Dense(vocab_size, 'softmax', kernel_initializer='glorot_uniform'))\n","    return model\n","\n","\n","def sentence_generation(model, t, current_word, n):\n","    init_word = current_word\n","    sentence = ''\n","    for _ in range(n):\n","        encoded = t.texts_to_sequences([current_word])[0]\n","        encoded = pad_sequences([encoded], maxlen=73, padding='pre')\n","        result = np.argmax(model.predict(encoded, verbose=0))\n","        word = ''\n","        for word, index in t.word_index.items():\n","            if index == result:\n","                break\n","        current_word += ' ' + word\n","        sentence += ' ' + word\n","    sentence = init_word + sentence\n","    return sentence\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Opq4ZbB_mwGI","colab_type":"code","colab":{}},"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","\n","if not os.path.isdir('./drive/My Drive/Colab/PoemGenerator/poems'):\n","    os.mkdir('./drive/My Drive/Colab/PoemGenerator/poems')\n","if not os.path.isdir('./drive/My Drive/Colab/PoemGenerator/checkpoints'):\n","    os.mkdir('./drive/My Drive/Colab/PoemGenerator/checkpoints')\n","\n","# get poem with crawler\n","if len(os.listdir('./drive/My Drive/Colab/PoemGenerator/poems')) < 50:\n","    get_poem()\n","\n","# read text\n","text = []\n","for i in range(1, 51):\n","    n = '1'\n","    if i < 10:\n","        n = '0' + str(i)\n","    else:\n","        n = str(i)\n","\n","    with open('./drive/My Drive/Colab/PoemGenerator/poems/poem' + n + '.txt', 'r', encoding='utf-8') as f:\n","        while 1:\n","            tmp = f.readline()\n","            text.append(tmp[:-1])\n","            if tmp == '':\n","                break\n","\n","# Tokenizer\n","t = Tokenizer()\n","t.fit_on_texts(text)\n","vocab_size = len(t.word_index) + 1\n","\n","# make sequences\n","sequences = list()\n","for line in text:\n","    encoded = t.texts_to_sequences([line])[0]\n","    for i in range(1, len(encoded)):\n","        sequence = encoded[:i + 1]\n","        sequences.append(sequence)\n","\n","idx2word = {}\n","for key, value in t.word_index.items():\n","    idx2word[value] = key\n","\n","max_len = max(len(ln) for ln in sequences)\n","sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n","\n","# split sequences into X, Y\n","sequences = np.array(sequences)\n","X = sequences[:, :-1]\n","Y = sequences[:, -1]\n","Y = to_categorical(Y, num_classes=vocab_size)\n","\n","checkpoint_dir = './drive/My Drive/Colab/PoemGenerator/checkpoints'\n","checkpoint_prefix = os.path.join(checkpoint_dir, 'cpkt')\n","checkpoint_callback = ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True\n",")\n","\n","model = build_model(vocab_size, max_len)\n","\n","# train model\n","if len(os.listdir('./drive/My Drive/Colab/PoemGenerator/checkpoints')) == 0:\n","    model.summary()\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.fit(X, Y, batch_size=256, epochs=250, callbacks=[checkpoint_callback], verbose=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","\n","# get word from input and generate text(50 words)\n","# input 'x' to stop\n","while True:\n","    word = input('시작 단어 입력(종료: x): ')\n","    if word == 'x':\n","        break\n","    else:\n","        text_len = int(input('단어 수 입력: '))\n","        print(sentence_generation(model, t, word, text_len))\n","        print('')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QBQTe35s6bZ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}